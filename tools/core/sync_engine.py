import os
import json
import asyncio
import edge_tts
from pymediainfo import MediaInfo
from pathlib import Path

# é…ç½®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
PROJECT_JSON = PROJECT_ROOT / "remotion-studio/src/projects/demo.json"
ASSETS_DIR = PROJECT_ROOT / "remotion-studio/public/assets/projects/demo"
AUDIO_DIR = ASSETS_DIR / "audio/segments"
SRT_PATH = PROJECT_ROOT / "remotion-studio/src/projects/demo_subtitles.srt"

# TTS é…ç½®
VOICE = "zh-CN-YunyangNeural"
RATE = "+0%"
VOLUME = "+0%"

async def generate_voice(text, output_file):
    """è°ƒç”¨ Edge-TTS ç”Ÿæˆè¯­éŸ³"""
    communicate = edge_tts.Communicate(text, VOICE, rate=RATE, volume=VOLUME)
    await communicate.save(output_file)

def get_audio_duration(file_path):
    """è·å–éŸ³é¢‘æ–‡ä»¶çš„å®é™…æ—¶é•¿ï¼ˆç§’ï¼‰"""
    media_info = MediaInfo.parse(file_path)
    for track in media_info.tracks:
        if track.track_type == "Audio":
            return float(track.duration) / 1000.0
    return 0.0

def format_srt_time(seconds):
    """å°†ç§’æ•°è½¬ä¸º SRT æ—¶é—´æ ¼å¼: HH:MM:SS,mmm"""
    ms = int((seconds % 1) * 1000)
    s = int(seconds % 60)
    m = int((seconds // 60) % 60)
    h = int(seconds // 3600)
    return f"{h:02}:{m:02}:{s:02},{ms:03}"

async def sync_all():
    print("ğŸ¬ [SyncEngine] å¯åŠ¨åŒæ­¥å¼•æ“...")
    
    if not os.path.exists(PROJECT_JSON):
        print(f"âŒ æ‰¾ä¸åˆ°é¡¹ç›®æ–‡ä»¶: {PROJECT_JSON}")
        return

    with open(PROJECT_JSON, "r", encoding="utf-8") as f:
        project = json.load(f)

    # 1. æå–å­—å¹•è½¨é“ä½œä¸ºæºå¤´
    subtitles_track = next((t for t in project["tracks"] if t["id"] == "track_subtitles"), None)
    if not subtitles_track:
        print("âŒ è½¨é“é…ç½®ä¸­æœªæ‰¾åˆ° track_subtitles")
        return

    os.makedirs(AUDIO_DIR, exist_ok=True)
    
    new_sub_clips = []
    new_voice_clips = []
    current_time = 0.0
    srt_content = []

    print(f"ğŸ™ï¸ æ­£åœ¨æ ¹æ®æ–‡æœ¬é‡æ–°ç”ŸæˆéŸ³é¢‘ (å…± {len(subtitles_track['clips'])} æ®µ)...")

    for i, clip in enumerate(subtitles_track["clips"]):
        text = clip.get("text", "").strip()
        if not text: continue

        audio_filename = f"s{i+1:02}.mp3"
        audio_path = AUDIO_DIR / audio_filename
        
        # A. ç”ŸæˆéŸ³é¢‘
        await generate_voice(text, str(audio_path))
        
        # B. è·å–çœŸå®æ—¶é•¿
        duration = get_audio_duration(str(audio_path))
        
        # C. æ„é€ æ–°çš„æ—¶é—´è½´ç‰‡æ®µ (å¹¶ä¿ç•™åŸæœ‰å±æ€§å¦‚ position, style)
        start_time = round(current_time, 3)
        duration = round(duration, 3)
        
        # å…‹éš†åŸå§‹å¯¹è±¡å‰¯æœ¬ä»¥ä¿ç•™æ ·å¼
        new_clip = clip.copy()
        new_clip.update({
            "start": start_time,
            "duration": duration
        })
        new_sub_clips.append(new_clip)

        # æ„é€ éŸ³é¢‘ç‰‡æ®µ (éŸ³é¢‘ç‰‡æ®µç›¸å¯¹ç®€å•ï¼Œä¸»è¦å¯¹é½æ—¶é—´)
        new_voice_clips.append({
            "id": f"voice_{i+1}",
            "type": "audio",
            "path": f"/assets/projects/demo/audio/segments/{audio_filename}",
            "start": start_time,
            "duration": duration,
            "volume": 1.0
        })

        # æ„å»º SRT å†…å®¹
        srt_content.append(f"{i+1}")
        srt_content.append(f"{format_srt_time(start_time)} --> {format_srt_time(start_time + duration)}")
        srt_content.append(f"{text}\n")

        current_time += duration

    # 2. æ¼£æ¼ªæ›´æ–°ï¼šåŒæ­¥è§†é¢‘èƒŒæ™¯è½¨é“
    total_duration = current_time
    video_track = next((t for t in project["tracks"] if t.get("type") == "video"), None)
    if video_track and len(video_track["clips"]) > 0:
        # ç®€å•é€»è¾‘ï¼šå¹³åˆ†æ€»æ—¶é•¿ç»™ç°æœ‰å›¾ç‰‡
        avg_dur = total_duration / len(video_track["clips"])
        v_time = 0.0
        for v_clip in video_track["clips"]:
            v_clip["start"] = round(v_time, 3)
            v_clip["duration"] = round(avg_dur, 3)
            v_time += avg_dur

    # 3. æ›´æ–°é¡¹ç›®æ€»æ—¶é•¿
    project["duration"] = round(total_duration, 3)
    
    # æŸ¥æ‰¾å¹¶æ›´æ–°éŸ³é¢‘è½¨é“
    voice_track = next((t for t in project["tracks"] if t["id"] == "track_voiceover"), None)
    if voice_track:
        voice_track["clips"] = new_voice_clips
    
    # å›å†™å­—å¹•è½¨é“ï¼ˆæ­¤æ—¶å·²å¸¦æœ‰æ—¶é•¿ä¿¡æ¯ï¼‰
    subtitles_track["clips"] = new_sub_clips

    # 4. ä¿å­˜æ–‡ä»¶
    with open(PROJECT_JSON, "w", encoding="utf-8") as f:
        json.dump(project, f, ensure_ascii=False, indent=4)
    
    with open(SRT_PATH, "w", encoding="utf-8") as f:
        f.write("\n".join(srt_content))

    print(f"âœ… åŒæ­¥å®Œæˆï¼")
    print(f"â±ï¸ æ€»æ—¶é•¿: {project['duration']}s")
    print(f"ğŸ“„ æ›´æ–°äº† {PROJECT_JSON.name}")
    print(f"ğŸ“„ æ›´æ–°äº† {SRT_PATH.name}")

if __name__ == "__main__":
    asyncio.run(sync_all())
