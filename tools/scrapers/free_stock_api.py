"""
å…è´¹ç´ æä¸‹è½½å·¥å…· - ä½¿ç”¨çœŸå® API
æ”¯æŒ Pexels å’Œ Pixabay
"""

import requests
from pathlib import Path
from typing import List, Dict, Optional
import json
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class PixabayAPI:
    """Pixabay è§†é¢‘ç´ æ API å°è£…"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– Pixabay API
        
        Args:
            api_key: API Key (å¯é€‰,é»˜è®¤ä»ç¯å¢ƒå˜é‡ PIXABAY_API_KEY è¯»å–)
        """
        self.api_key = api_key or os.getenv('PIXABAY_API_KEY')
        if not self.api_key:
            raise ValueError(
                "æœªæ‰¾åˆ° Pixabay API Key!\n"
                "è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® PIXABAY_API_KEY,\n"
                "æˆ–è®¿é—® https://pixabay.com/api/docs/ è·å–å…è´¹ API key"
            )
        self.base_url = "https://pixabay.com/api/videos/"
    
    def search_videos(
        self,
        query: str,
        per_page: int = 20,
        page: int = 1
    ) -> List[Dict]:
        """æœç´¢è§†é¢‘ç´ æ
        
        æ³¨æ„: Pixabay è§†é¢‘ API çš„ per_page èŒƒå›´æ˜¯ 3-200
        """
        # ç¡®ä¿ per_page åœ¨æœ‰æ•ˆèŒƒå›´å†…
        per_page = max(3, min(200, per_page))
        
        params = {
            "key": self.api_key,
            "q": query,
            "per_page": per_page,
            "page": page
        }
        
        try:
            response = requests.get(self.base_url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            return data.get("hits", [])
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 400:
                print("âŒ API Key æ— æ•ˆ,è¯·è®¿é—® https://pixabay.com/api/docs/ è·å–å…è´¹ API key")
                print("   ç„¶åä¿®æ”¹ free_stock_api.py ä¸­çš„ api_key å‚æ•°")
            raise
    
    def get_best_quality_url(self, video: Dict) -> Optional[str]:
        """è·å–æœ€ä½³è´¨é‡çš„ä¸‹è½½é“¾æ¥"""
        videos = video.get("videos", {})
        
        # ä¼˜å…ˆçº§: large > medium > small
        for quality in ["large", "medium", "small", "tiny"]:
            if quality in videos and videos[quality].get("url"):
                return videos[quality]["url"]
        
        return None


class PexelsAPI:
    """
    Pexels API å°è£…
    
    ä½¿ç”¨æ–¹æ³•:
    1. è®¿é—® https://www.pexels.com/api/
    2. æ³¨å†Œå…è´¹è´¦å·
    3. è·å– API Key
    4. åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® PEXELS_API_KEY
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– Pexels API
        
        Args:
            api_key: API Key (å¯é€‰,é»˜è®¤ä»ç¯å¢ƒå˜é‡ PEXELS_API_KEY è¯»å–)
        """
        self.api_key = api_key or os.getenv('PEXELS_API_KEY')
        if not self.api_key:
            raise ValueError(
                "æœªæ‰¾åˆ° Pexels API Key!\n"
                "è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® PEXELS_API_KEY,\n"
                "æˆ–è®¿é—® https://www.pexels.com/api/ è·å–å…è´¹ API key"
            )
        self.base_url = "https://api.pexels.com/videos"
        self.headers = {"Authorization": self.api_key}
    
    def search_videos(
        self, 
        query: str, 
        per_page: int = 15,
        page: int = 1,
        orientation: Optional[str] = None
    ) -> List[Dict]:
        """æœç´¢è§†é¢‘ç´ æ"""
        url = f"{self.base_url}/search"
        params = {
            "query": query,
            "per_page": per_page,
            "page": page
        }
        
        if orientation:
            params["orientation"] = orientation
            
        response = requests.get(url, headers=self.headers, params=params, timeout=10)
        response.raise_for_status()
        
        data = response.json()
        return data.get("videos", [])
    
    def get_best_quality_url(self, video: Dict, min_width: int = 1920) -> Optional[str]:
        """è·å–æœ€ä½³è´¨é‡çš„ä¸‹è½½é“¾æ¥"""
        video_files = video.get("video_files", [])
        
        # æŒ‰å®½åº¦é™åºæ’åº
        sorted_files = sorted(
            video_files,
            key=lambda x: x.get("width", 0),
            reverse=True
        )
        
        # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ»¡è¶³æœ€å°å®½åº¦è¦æ±‚çš„
        for file in sorted_files:
            if file.get("width", 0) >= min_width and file.get("link"):
                return file["link"]
        
        # å¦‚æœæ²¡æœ‰æ»¡è¶³è¦æ±‚çš„,è¿”å›æœ€é«˜è´¨é‡çš„
        if sorted_files:
            return sorted_files[0].get("link")
        
        return None


def download_video(url: str, output_path: Path) -> bool:
    """ä¸‹è½½è§†é¢‘æ–‡ä»¶"""
    try:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        print(f"â¬ æ­£åœ¨ä¸‹è½½: {output_path.name}")
        response = requests.get(url, stream=True, timeout=30)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        downloaded = 0
        
        with open(output_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
                downloaded += len(chunk)
                if total_size > 0:
                    percent = (downloaded / total_size) * 100
                    print(f"\r  è¿›åº¦: {percent:.1f}%", end='')
        
        print(f"\nâœ… ä¸‹è½½æˆåŠŸ: {output_path}")
        return True
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½å¤±è´¥: {e}")
        return False


def batch_download_from_pixabay(
    keywords: List[str],
    output_dir: Path,
    videos_per_keyword: int = 1
):
    """
    æ‰¹é‡ä» Pixabay ä¸‹è½½è§†é¢‘
    
    Args:
        keywords: å…³é”®è¯åˆ—è¡¨ (è‹±æ–‡)
        output_dir: è¾“å‡ºç›®å½•
        videos_per_keyword: æ¯ä¸ªå…³é”®è¯ä¸‹è½½å‡ ä¸ªè§†é¢‘
    """
    pixabay = PixabayAPI()
    
    for keyword in keywords:
        print(f"\nğŸ” æœç´¢: '{keyword}'")
        try:
            # ç¡®ä¿ per_page è‡³å°‘ä¸º 3 (Pixabay API è¦æ±‚)
            actual_per_page = max(3, videos_per_keyword)
            videos = pixabay.search_videos(keyword, per_page=actual_per_page)
            
            if not videos:
                print(f"  âš ï¸ æœªæ‰¾åˆ°ç›¸å…³è§†é¢‘")
                continue
            
            print(f"  æ‰¾åˆ° {len(videos)} ä¸ªè§†é¢‘")
            
            for i, video in enumerate(videos[:videos_per_keyword]):
                url = pixabay.get_best_quality_url(video)
                if url:
                    filename = f"{keyword.replace(' ', '_')}_{i+1}.mp4"
                    output_path = output_dir / filename
                    download_video(url, output_path)
        
        except Exception as e:
            print(f"  âŒ æœç´¢å¤±è´¥: {e}")


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # å®šä¹‰è¦ä¸‹è½½çš„ç´ æå…³é”®è¯
    keywords = [
        "stressed office worker",
        "video editing timeline",
        "beach waves",
        "running beach",
        "bamboo forest"
    ]
    
    # è¾“å‡ºç›®å½• - æŒ‰é¡¹ç›®ç»„ç»‡
    project_name = "demo"  # é¡¹ç›®åç§°
    output_dir = Path(f"remotion-studio/public/assets/projects/{project_name}/videos")
    
    print("=" * 60)
    print("å…è´¹ç´ ææ‰¹é‡ä¸‹è½½å·¥å…·")
    print("=" * 60)
    print(f"é¡¹ç›®: {project_name}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"å…³é”®è¯æ•°é‡: {len(keywords)}")
    print("=" * 60)
    
    # å¼€å§‹ä¸‹è½½
    batch_download_from_pixabay(keywords, output_dir, videos_per_keyword=1)
    
    print("\n" + "=" * 60)
    print("âœ… ä¸‹è½½å®Œæˆ!")
    print("=" * 60)
